#  EduMood â€“ Students Emotion Recognition System

### *AI-Based Real-Time Classroom Emotion Analytics*

---

## ðŸ“Œ 1. Overview

**EduMood** is an AI-powered system designed to recognize and analyze studentsâ€™ facial emotions in real time using a webcam.
The system captures video frames, detects faces, predicts emotions, stores aggregated session statistics, and visualizes the results through an interactive Streamlit dashboard.

This project is developed as part of the course:
**CSC â€” Design of Artificial Intelligence Systems**,
following the full **AI lifecycle** methodology.

---

## ðŸ“Œ 2. System Purpose

EduMood serves as an educational AI prototype that demonstrates:

* Real-time facial emotion recognition
* Classroom-level emotional analytics
* Data aggregation & visualization
* Integration of pre-trained models into a complete AI system

The system builds a structured analytic pipeline similar to Kevin Aguirreâ€™s project, but adapted to our own architecture and academic requirements.

---

## ðŸ“Œ 3. High-Level System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Webcam Input    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Frames
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EduMoodRecognizer  â”‚
â”‚ â”€ Face detection    â”‚
â”‚ â”€ Emotion inference â”‚
â”‚ â”€ Frame sampling    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Emotion record
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EduMoodSessionStatsâ”‚
â”‚ â”€ Stores all rows  â”‚
â”‚ â”€ Aggregates data  â”‚
â”‚ â”€ Converts to DF   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Pandas DataFrame
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Streamlit UI   â”‚
â”‚ â”€ Metrics          â”‚
â”‚ â”€ Charts           â”‚
â”‚ â”€ Tables           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“Œ 4. Technologies Used

| Component            | Purpose                               |
| -------------------- | ------------------------------------- |
| **Python 3.9+**      | Core development language             |
| **Streamlit**        | Interactive dashboard UI              |
| **streamlit-webrtc** | Real-time webcam streaming            |
| **DeepFace**         | Pre-trained emotion recognition model |
| **Pandas**           | Data storage & analysis               |
| **Altair**           | Visualization                         |
| **OpenCV**           | Frame processing                      |

---

## ðŸ“Œ 5. Emotion Model (DeepFace)

EduMood relies on **DeepFaceâ€™s built-in CNN expression model**, originally trained on **FER-2013**, to classify seven basic emotions:

* happy
* sad
* angry
* surprise
* neutral
* disgust
* fear

### Processing pipeline inside EduMood:

1. Detect a face
2. Crop the region of interest
3. Resize to 48Ã—48
4. Pass through DeepFace model
5. Receive emotion probabilities
6. Select the highest-scoring label

> No retraining or fine-tuning was done â€” the system uses the model exactly as provided.

---

## ðŸ“Œ 6. Data Strategy

EduMood follows a structured data-handling approach:

* Uses a **pre-trained** model instead of custom training
* Generates a **session-level log** of all detected emotions
* Each processed frame corresponds to one row in the internal DataFrame
* Summaries are computed using aggregation (sum/mean)
* The system imitates the data-handling strategy seen in Kevinâ€™s project

This ensures transparency and proper documentation for AI lifecycle reporting.

---

## ðŸ“Œ 7. Key Features

* ðŸ”µ **Real-time emotion recognition**
* ðŸ“Š **Live dashboard analytics**
* ðŸ§  **Session accumulation** (every detection recorded)
* ðŸŽš **Frame sampling** (analyze every N frames to reduce latency)
* ðŸªž **Mirror-mode** (camera flipped horizontally)
* ðŸ“ˆ **Bar charts, line charts, and KPI metrics**
* ðŸŽ¯ **Lightweight design suitable for classrooms and demos**

---

## ðŸ“Œ 8. Project Structure

Recommended clean project folder after removing unnecessary files:

```
EduMood/
â”‚
â”œâ”€â”€ app.py                     # Streamlit dashboard
â”œâ”€â”€ edumood_recognizer.py     # Recognition + session stats
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md                 # This documentation
â”œâ”€â”€ LICENSE                   # License file
â”‚
â””â”€â”€ assets/ (optional)        # Images / logos
```

---

## ðŸ“Œ 9. Installation

```bash
pip install -r requirements.txt
```

---

## ðŸ“Œ 10. Running the Application

```bash
streamlit run app.py
```

---

## ðŸ“Œ 11. Credits & References

This project integrates and refers to the following:

* DeepFace library (Serengil et al.)
* FER-2013 dataset (ICML 2013)
* Conceptual inspiration from Kevin Aguirreâ€™s **Facial Emotion Recognition App**
* Streamlit official documentation
* streamlit-webrtc official documentation

All external components are used under their respective licenses.

---

## ðŸ“Œ 12. License

The project is distributed for **academic and educational use only**.
Commercial use is not allowed unless a commercial license is obtained.
See the full terms in the **LICENSE** file.


